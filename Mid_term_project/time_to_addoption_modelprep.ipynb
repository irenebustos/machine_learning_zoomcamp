{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of number of days an animal (dog-cat) will spend in the shelter before being addopted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Data cleaning and preparation](#1)\n",
    "2. [EDA](#2)\n",
    "3. [Model evaluation](#3)   \n",
    "    3.1 [Features selection](#31)  \n",
    "    3.2 [Training models](#32)  \n",
    "        - 3.2.1 [Linear Regression](#321)  \n",
    "        - 3.2.2 [Random Forest](#322)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read prepared dataset\n",
    "df = pd.DataFrame(pd.read_csv('data.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Data types & formats inside df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_limit_breed_words = 80\n",
    "percentage_limit_breed_words_combination = 0.8  \n",
    "percentage_limit_breed_words_unique = 2 \n",
    "percentage_limit_color = 0.05  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creating function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'age_upon_intake'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'age_upon_intake'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 63\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Handle unknown units\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_in_months\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_upon_intake\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(convert_to_months) \n\u001b[1;32m     64\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_in_months\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_in_months\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mabs()\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m##########################\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# Breed group creation \u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;66;03m##########################\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# Hair type\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'age_upon_intake'"
     ]
    }
   ],
   "source": [
    "\n",
    "datetime_columns = ['datetime_intake', 'datetime_outcome']\n",
    "# convert the datetime columns to datetime type\n",
    "for column in datetime_columns:\n",
    "    df[column] = pd.to_datetime(df[column])\n",
    "datetime_columns\n",
    "\n",
    "# rest of the columns from dataframe that are not datetime categorical columns\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "categorical_columns\n",
    "\n",
    "for column in categorical_columns:\n",
    "    df[column] = df[column].str.lower()\n",
    "\n",
    "##########################\n",
    "# days in shelter\n",
    "df['days_in_shelter'] = (df['datetime_outcome'] - df['datetime_intake']).dt.days\n",
    "\n",
    "##########################\n",
    "# castrated\n",
    "#########################\n",
    "def castrated_status(row):\n",
    "    if 'neutered' in row or 'spayed' in row:\n",
    "        return 'yes'\n",
    "    else:\n",
    "        return 'no'\n",
    "\n",
    "df['castrated'] = df['sex_upon_intake'].apply(castrated_status)\n",
    "df['is_castrated'] = df['castrated'].apply(lambda x: 1 if x =='yes' else 0)\n",
    "\n",
    "##########################\n",
    "# sex upon intake\n",
    "##########################\n",
    "def sex_upon_intake(row):\n",
    "    if 'female' in row:\n",
    "        return 'female'\n",
    "    elif 'male' in row:\n",
    "        return 'male'\n",
    "    else:\n",
    "        return 'unknown'\n",
    "\n",
    "df['sex_upon_intake'] = df['sex_upon_intake'].apply(sex_upon_intake) \n",
    "\n",
    "#############################################\n",
    "# Age in months when the animal was taken in\n",
    "#############################################\n",
    "def convert_to_months(age):\n",
    "    # Split the age into value and unit\n",
    "    parts = age.split()\n",
    "    if len(parts) != 2:  # Handle unexpected formats\n",
    "        return None\n",
    "    \n",
    "    value, unit = int(parts[0]), parts[1].lower()\n",
    "    \n",
    "    # Convert the age to months\n",
    "    if 'year' in unit:\n",
    "        return value * 12\n",
    "    elif 'month' in unit:\n",
    "        return value \n",
    "    elif 'week' in unit:\n",
    "        return value / 4\n",
    "    elif 'day' in unit:\n",
    "        return value / 30\n",
    "    else:\n",
    "        return None  # Handle unknown units\n",
    "\n",
    "df['age_in_months'] = df['age_upon_intake'].apply(convert_to_months) \n",
    "df['age_in_months'] = df['age_in_months'].abs()\n",
    "\n",
    "##########################\n",
    "# Breed group creation \n",
    "##########################\n",
    "# Hair type\n",
    "df['hair_type'] = df['breed'].apply(\n",
    "    lambda x: 'long' if 'longhair' in x else 'short' if 'shorthair' in x\n",
    "    else 'medium' if 'medium hair' in x else 'unknown'\n",
    ")\n",
    "\n",
    "# Mix breed\n",
    "df['mix_breed'] = df['breed'].apply(lambda x: 'mix' if 'mix' in x else 'not mix')\n",
    "df['is_mix_breed'] = df['mix_breed'].apply(lambda x: 1 if x == 'mix' else 0)\n",
    "\n",
    "# Miniature breed\n",
    "df['miniature'] = df['breed'].apply(lambda x: 'miniature' if 'miniature' in x else 'non-miniature')\n",
    "df['is_miniature'] = df['miniature'].apply(lambda x: 1 if x == 'miniature' else 0)\n",
    "\n",
    "# Domestic breed\n",
    "df['domestic'] = df['breed'].apply(lambda x: 'domestic' if 'domestic' in x else 'non-domestic')\n",
    "df['is_domestic'] = df['domestic'].apply(lambda x: 1 if x == 'domestic' else 0)\n",
    "\n",
    "# Clean up breed column by removing specific words\n",
    "words_to_remove = ['mix', 'shorthair', 'longhair', 'medium hair', 'miniature', 'domestic', 'dog', 'cat']\n",
    "for word in words_to_remove:\n",
    "    df['breed'] = df['breed'].str.replace(word, '', regex=True).str.strip()\n",
    "\n",
    "# Tokenize and count words in the breed column\n",
    "all_words = df['breed'].str.split(expand=True).stack()\n",
    "word_counts = Counter(all_words)\n",
    "word_freq_df = pd.DataFrame(word_counts.items(), columns=['Word', 'Frequency']).sort_values(by='Frequency', ascending=False)\n",
    "\n",
    "# Calculate percentage and cumulative percentage of word frequencies\n",
    "total_words = word_freq_df['Frequency'].sum()\n",
    "word_freq_df['Percentage'] = (word_freq_df['Frequency'] / total_words) * 100\n",
    "word_freq_df['Cumulative Percentage'] = word_freq_df['Percentage'].cumsum()\n",
    "\n",
    "# Select important words based on cumulative percentage limit\n",
    "important_words_df = word_freq_df[word_freq_df['Cumulative Percentage'] <= percentage_limit_breed_words]\n",
    "\n",
    "# Generate pairs of words in the breed column\n",
    "df['breed_tokenized'] = df['breed'].str.split()\n",
    "word_pairs = df['breed_tokenized'].apply(lambda x: list(combinations(x, 2)))\n",
    "\n",
    "all_pairs = [pair for pairs in word_pairs for pair in pairs]\n",
    "pair_counts = Counter(all_pairs)\n",
    "pair_freq_df = pd.DataFrame(pair_counts.items(), columns=['Pair', 'Frequency']).sort_values(by='Frequency', ascending=False)\n",
    "\n",
    "# Calculate percentage and cumulative percentage of pair frequencies\n",
    "total_pairs = pair_freq_df['Frequency'].sum()\n",
    "pair_freq_df['Percentage'] = (pair_freq_df['Frequency'] / total_pairs) * 100\n",
    "pair_freq_df['Cumulative Percentage'] = pair_freq_df['Percentage'].cumsum()\n",
    "\n",
    "# Select frequent pairs based on percentage limit\n",
    "frequent_pairs_df = pair_freq_df[pair_freq_df['Percentage'] >= percentage_limit_breed_words_combination]\n",
    "\n",
    "# Function to assign a breed group based on frequent pairs\n",
    "def assign_breed_group(breed, frequent_pairs):\n",
    "    for pair in frequent_pairs:\n",
    "        if all(word in breed for word in pair):\n",
    "            return f\"{pair[0]}_{pair[1]}\"\n",
    "    return None\n",
    "\n",
    "df['breed_group1'] = df['breed'].apply(lambda x: assign_breed_group(x, frequent_pairs_df['Pair'].tolist()))\n",
    "\n",
    "# Clean up the breed column by removing frequent pairs\n",
    "top_combinations = frequent_pairs_df['Pair'].tolist()\n",
    "\n",
    "def remove_combinations(breed, combinations):\n",
    "    for pair in combinations:\n",
    "        if all(word in breed for word in pair):\n",
    "            breed = breed.replace(f\"{pair[0]} {pair[1]}\", \"\")\n",
    "    return breed.strip()\n",
    "\n",
    "df['breed'] = df['breed'].apply(lambda x: remove_combinations(x, top_combinations))\n",
    "\n",
    "# Recalculate frequent words after cleaning the breed column\n",
    "df_no_breed_group = df[df['breed_group1'].isna()]\n",
    "all_words = df_no_breed_group['breed'].str.split(expand=True).stack()\n",
    "word_counts = Counter(all_words)\n",
    "\n",
    "word_freq_df = pd.DataFrame(word_counts.items(), columns=['Word', 'Frequency']).sort_values(by='Frequency', ascending=False)\n",
    "\n",
    "# Select important words based on frequency percentage limit\n",
    "total_words = word_freq_df['Frequency'].sum()\n",
    "word_freq_df['Percentage'] = (word_freq_df['Frequency'] / total_words) * 100\n",
    "word_freq_df['Cumulative Percentage'] = word_freq_df['Percentage'].cumsum()\n",
    "frequent_words_df = word_freq_df[word_freq_df['Percentage'] >= percentage_limit_breed_words_unique]\n",
    "\n",
    "# Exclude specific words from the frequent words\n",
    "exclude_words = ['bull', 'pit']\n",
    "frequent_words_df = frequent_words_df[~frequent_words_df['Word'].isin(exclude_words)]\n",
    "\n",
    "# Function to assign breed group based on frequent words\n",
    "def assign_breed_word(breed, frequent_words):\n",
    "    for word in frequent_words:\n",
    "        if word in breed:\n",
    "            return word\n",
    "    return None\n",
    "\n",
    "df['breed_group2'] = df['breed'].apply(lambda x: assign_breed_word(x, frequent_words_df['Word'].tolist()))\n",
    "\n",
    "# Combine breed groups into a single column\n",
    "df['breed_group'] = df['breed_group1'].fillna(df['breed_group2']).fillna('Other')\n",
    "\n",
    "# Group breeds into specific categories\n",
    "df['breed_group'] = df['breed_group'].apply(\n",
    "    lambda x: 'larger_dangerous' if 'pit' in x or 'bull' in x or 'american_terrier' in x\n",
    "    else 'small_dog' if 'chihuahua' in x or 'terrier' in x or 'dachshund' in x or 'poodle' in x or 'jack_russell' in x or 'russell_terrier' in x\n",
    "    else x\n",
    ")\n",
    "##########################\n",
    "# color \n",
    "#########################\n",
    "# Split the color column into components\n",
    "color_combinations = df['color'].str.split('/')  # Split by '/'\n",
    "split_colors = color_combinations.apply(lambda x: [part.split()[0] for part in x] if isinstance(x, list) else [])  # Extract first word of each component\n",
    "\n",
    "# Extract primary and secondary colors\n",
    "df['color_primary'] = split_colors.apply(lambda x: x[0] if len(x) > 0 else None)  # First color\n",
    "df['color_secondary'] = split_colors.apply(lambda x: x[1] if len(x) > 1 else None)  # Second color\n",
    "\n",
    "# Identify dominant single-color groups \n",
    "single_colors = df[df['color_secondary'].isnull()]['color_primary']  # Single-color records\n",
    "single_color_counts = single_colors.value_counts()\n",
    "total_single = single_colors.count()\n",
    "dominant_single_colors = single_color_counts[single_color_counts / total_single > percentage_limit_color].index\n",
    "\n",
    "df['single_color_group'] = df['color_primary'].apply(\n",
    "    lambda x: x if x in dominant_single_colors else 'other_single_colour'\n",
    ")\n",
    "\n",
    "# Process two-color combinations\n",
    "df['sorted_combination'] = df.apply(\n",
    "    lambda row: tuple(sorted([row['color_primary'], row['color_secondary']]))\n",
    "    if pd.notnull(row['color_secondary']) else None,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Identify dominant two-color combinations\n",
    "percentage_limit_combinations = 0.05\n",
    "combination_counts = df['sorted_combination'].dropna().value_counts()\n",
    "total_combinations = combination_counts.sum()\n",
    "dominant_combinations = combination_counts[combination_counts / total_combinations > percentage_limit_color].index\n",
    "\n",
    "df['combination_group'] = df['sorted_combination'].apply(\n",
    "    lambda x: x if x in dominant_combinations else 'other_multiple_color'\n",
    ")\n",
    "\n",
    "# Final color group assignment\n",
    "df['color_group'] = df.apply(\n",
    "    lambda row: row['single_color_group']\n",
    "    if pd.isnull(row['sorted_combination'])\n",
    "    else row['combination_group'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Convert tuples in color group to readable strings\n",
    "df['color_group'] = df['color_group'].apply(\n",
    "    lambda x: ' & '.join(x) if isinstance(x, tuple) else x\n",
    ")\n",
    "\n",
    "##########################\n",
    "# in sex_upon_intake column, just add if is male or not to avoid having unknown values\n",
    "df['is_male'] = df['sex_upon_intake'].apply(lambda x: 1 if x =='male' else 0) \n",
    "# condition at intake: grouping medical (med attn and medical), normal, sick_injured and rest (other)\n",
    "df['intake_condition_group'] = df['intake_condition'].apply(\n",
    "    lambda x: 'normal' if 'normal' in x \n",
    "    else 'sick_injured' if 'sick' in x \n",
    "    else 'sick_injured' if 'injured' in x \n",
    "    else 'medical' if 'medical' in x \n",
    "    else 'medical' if 'med attn' in x  \n",
    "    else 'nursing' if 'nursing' in x \n",
    "    else 'nursing' if 'neonatal' in x \n",
    "    else 'other')\n",
    "\n",
    "# group intake type: stray, owner surrended and Other\n",
    "df['intake_type_group'] = df['intake_type'].apply(\n",
    "    lambda x: 'stray' if 'stray' in x \n",
    "    else 'owner surrender' if 'owner surrender' in x \n",
    "    else 'other'\n",
    ")\n",
    "\n",
    "####################\n",
    "# is dog\n",
    "df['is_dog'] = df['animal_type'].apply(lambda x: 1 if x =='dog' else 0)\n",
    "######################\n",
    "# day of intake mothn and day of week\n",
    "df['day_of_week_in'] = df['datetime_intake'].dt.day_of_week\n",
    "df['month_in'] = df['datetime_intake'].dt.month\n",
    "\n",
    "#####################\n",
    "# Function to calculate the overlap count for a given row, considering animal_type\n",
    "def count_overlapping_by_type(row, df):\n",
    "    overlapping = df[\n",
    "        (df['datetime_intake'] <= row['datetime_outcome']) &  # Shelter intake is before or during this outcome\n",
    "        (df['datetime_outcome'] >= row['datetime_intake']) &  # Shelter outcome is after or during this intake\n",
    "       ##(df['animal_type'] == row['animal_type']) &           # Same animal type\n",
    "       ## (df['breed_group'] == row['breed_group']) &        # Same day of the week\n",
    "        (df.index != row.name)  # Exclude the current record itself\n",
    "    ]\n",
    "    return len(overlapping) \n",
    "df['animals_in_shelter'] = df.apply(lambda row: count_overlapping_by_type(row, df), axis=1)\n",
    "\n",
    "# Drop unused columns\n",
    "cols_to_drop = ['name', 'age_upon_intake', 'breed_group1', 'breed_group2', 'breed', 'breed_tokenized', 'color', 'color_primary', 'color_secondary', 'single_color_group', 'sorted_combination', 'combination_group']\n",
    "df.drop(columns=cols_to_drop, errors='ignore', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # datetime columns: datetime_intake, datetime_outcome\n",
    "# datetime_columns = ['datetime_intake', 'datetime_outcome']\n",
    "# # convert the datetime columns to datetime type\n",
    "# for column in datetime_columns:\n",
    "#     df[column] = pd.to_datetime(df[column])\n",
    "# datetime_columns\n",
    "\n",
    "# # rest of the columns from dataframe that are not datetime categorical columns\n",
    "# categorical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "# categorical_columns\n",
    "\n",
    "# for column in categorical_columns:\n",
    "#     df[column] = df[column].str.lower()\n",
    "\n",
    "# ##########################\n",
    "# # days in shelter\n",
    "# df['days_in_shelter'] = (df['datetime_outcome'] - df['datetime_intake']).dt.days\n",
    "\n",
    "# ##########################\n",
    "# # castrated\n",
    "# def castrated_status(row):\n",
    "#     if 'neutered' in row or 'spayed' in row:\n",
    "#         return 'yes'\n",
    "#     else:\n",
    "#         return 'no'\n",
    "\n",
    "# df['castrated'] = df['sex_upon_intake'].apply(castrated_status)\n",
    "# df['is_castrated'] = df['castrated'].apply(lambda x: 1 if x =='yes' else 0)\n",
    "\n",
    "# ##########################\n",
    "# # sex upon intake\n",
    "# def sex_upon_intake(row):\n",
    "#     if 'female' in row:\n",
    "#         return 'female'\n",
    "#     elif 'male' in row:\n",
    "#         return 'male'\n",
    "#     else:\n",
    "#         return 'unknown'\n",
    "\n",
    "# df['sex_upon_intake'] = df['sex_upon_intake'].apply(sex_upon_intake) \n",
    "\n",
    "# ##########################\n",
    "# # age upon intake\n",
    "# def convert_to_months(age):\n",
    "#     # Split the age into value and unit\n",
    "#     parts = age.split()\n",
    "#     if len(parts) != 2:  # Handle unexpected formats\n",
    "#         return None\n",
    "    \n",
    "#     value, unit = int(parts[0]), parts[1].lower()\n",
    "    \n",
    "#     # Convert the age to months\n",
    "#     if 'year' in unit:\n",
    "#         return value * 12\n",
    "#     elif 'month' in unit:\n",
    "#         return value \n",
    "#     elif 'week' in unit:\n",
    "#         return value / 4\n",
    "#     elif 'day' in unit:\n",
    "#         return value / 30\n",
    "#     else:\n",
    "#         return None  # Handle unknown units\n",
    "\n",
    "# df['age_in_months'] = df['age_upon_intake'].apply(convert_to_months) \n",
    "# df['age_in_months'] = df['age_in_months'].abs()\n",
    "\n",
    "# ##########################\n",
    "# # breed and other properties from it\n",
    "# # 'hair_type'\n",
    "# df['hair_type'] = df['breed'].apply(\n",
    "#     lambda x: 'long' if 'longhair' in x else 'short' if 'shorthair' in x\n",
    "#       else 'medium' if 'medium hair' in x else 'unknown')\n",
    "\n",
    "# # mix breed column\n",
    "# df['mix_breed'] = df['breed'].apply(lambda x: 'mix' if 'mix' in x else 'not mix') \n",
    "# df['is_mix_breed'] = df['mix_breed'].apply(lambda x: 1 if x =='mix' else 0) \n",
    "# # miniature breed column\n",
    "# df['miniature'] = df['breed'].apply(lambda x: 'miniature' if 'miniature' in x else 'non-miniature')\n",
    "# df['is_miniature'] = df['miniature'].apply(lambda x: 1 if x =='miniature' else 0)\n",
    "# # domestic breed column\n",
    "# df['domestic'] = df['breed'].apply(lambda x: 'domestic' if 'domestic' in x else 'non-domestic')\n",
    "# df['is_domestic'] = df['domestic'].apply(lambda x: 1 if x =='domestic' else 0)\n",
    "\n",
    "\n",
    "# words_to_remove = ['mix', 'shorthair', 'longhair', 'medium hair', 'miniature', 'domestic','dog','cat']\n",
    "# for word in words_to_remove:\n",
    "#     df['breed'] = df['breed'].str.replace(word, '').str.strip()\n",
    "\n",
    "# # Split the breed column into individual words\n",
    "# all_words = df['breed'].str.split(expand=True).stack()\n",
    "# word_counts = Counter(all_words)\n",
    " \n",
    "# word_freq_df = pd.DataFrame(word_counts.items(), columns=['Word', 'Frequency']).sort_values(by='Frequency', ascending=False)\n",
    " \n",
    "# total_words = word_freq_df['Frequency'].sum()\n",
    "# word_freq_df['Percentage'] = (word_freq_df['Frequency'] / total_words) * 100\n",
    "# word_freq_df = word_freq_df.sort_values(by='Percentage', ascending=False)\n",
    "# word_freq_df['Cumulative Percentage'] = word_freq_df['Percentage'].cumsum()\n",
    "# important_words_df = word_freq_df[word_freq_df['Cumulative Percentage'] <= percentage_limit_breed_words]\n",
    "\n",
    "\n",
    "# # Tokenize each row in the breed column\n",
    "# df['breed_tokenized'] = df['breed'].str.split()\n",
    "# word_pairs = df['breed_tokenized'].apply(lambda x: list(combinations(x, 2)))\n",
    "\n",
    "# all_pairs = [pair for pairs in word_pairs for pair in pairs]\n",
    "\n",
    "# pair_counts = Counter(all_pairs)\n",
    "# pair_freq_df = pd.DataFrame(pair_counts.items(), columns=['Pair', 'Frequency']).sort_values(by='Frequency', ascending=False)\n",
    "# total_pairs = pair_freq_df['Frequency'].sum()\n",
    "# pair_freq_df['Percentage'] = (pair_freq_df['Frequency'] / total_pairs) * 100\n",
    "# pair_freq_df['Cumulative Percentage'] = pair_freq_df['Percentage'].cumsum()\n",
    "\n",
    "# # I decided to use 80% as the limit to cover the most important pairs\n",
    "# frequent_pairs_df = pair_freq_df[pair_freq_df['Percentage'] >= percentage_limit_breed_words_combination]\n",
    "\n",
    "# # Ensure the breed column and frequent pairs are processed correctly\n",
    "# def assign_breed_group(breed, frequent_pairs):\n",
    "#     for pair in frequent_pairs:\n",
    "#         if all(word in breed for word in pair):\n",
    "#             return f\"{pair[0]}_{pair[1]}\"\n",
    "#     return None\n",
    "\n",
    "# # Apply the function to the DataFrame\n",
    "# df['breed_group1'] = df['breed'].apply(lambda x: assign_breed_group(x, frequent_pairs_df['Pair'].tolist())) \n",
    "\n",
    "# top_combinations = frequent_pairs_df['Pair'].tolist()\n",
    "\n",
    "# def remove_combinations(breed, combinations):\n",
    "#     for pair in combinations:\n",
    "#         if all(word in breed for word in pair):\n",
    "#             breed = breed.replace(f\"{pair[0]} {pair[1]}\", \"\")\n",
    "#     return breed.strip()\n",
    "\n",
    "# # Apply the function to clean up the breed column\n",
    "# df['breed'] = df['breed'].apply(lambda x: remove_combinations(x, top_combinations))\n",
    "\n",
    "# # after cleaning the breed column, we can re-calculate the frequent words\n",
    "# df_no_breed_group = df[df['breed_group1'].isna()]\n",
    "\n",
    "# all_words = df_no_breed_group['breed'].str.split(expand=True).stack()\n",
    "# word_counts = Counter(all_words)\n",
    "\n",
    "\n",
    "# word_freq_df = pd.DataFrame(word_counts.items(), columns=['Word', 'Frequency']).sort_values(by='Frequency', ascending=False)\n",
    "# # I decided to use 2% as the limit to cover the most important words\n",
    "# total_words = word_freq_df['Frequency'].sum()\n",
    "# word_freq_df['Percentage'] = (word_freq_df['Frequency'] / total_words) * 100\n",
    "# word_freq_df = word_freq_df.sort_values(by='Percentage', ascending=False)\n",
    "# word_freq_df['Cumulative Percentage'] = word_freq_df['Percentage'].cumsum()\n",
    "# frequent_words_df = word_freq_df[word_freq_df['Percentage'] >= percentage_limit_breed_words_unique]\n",
    "\n",
    "# exclude_words = ['bull', 'pit'] \n",
    "# frequent_words_df = frequent_words_df[~frequent_words_df['Word'].isin(exclude_words)]\n",
    "\n",
    "# # Ensure the breed column and frequent pairs are processed correctly\n",
    "# def assign_breed_word(breed, frequent_words):\n",
    "#     for word in frequent_words:\n",
    "#         if word in breed:\n",
    "#             return word\n",
    "#     return None\n",
    "# # Apply the function to the DataFrame\n",
    "# df['breed_group2'] = df['breed'].apply(lambda x: assign_breed_word(x, frequent_words_df['Word'].tolist()))\n",
    "\n",
    "# df['breed_group'] = df['breed_group1'].fillna(df['breed_group2'])\n",
    "\n",
    "# # assign the breed_group to other if it is still null\n",
    "# df['breed_group'] = df['breed_group'].fillna('Other')\n",
    "\n",
    "# df['breed_group'] = df['breed_group'].apply(\n",
    "#     lambda x: 'larger_dangerous' if 'pit' in x \n",
    "#     else 'larger_dangerous' if 'bull' in x \n",
    "#     else 'larger_dangerous' if 'american_terrier' in x  \n",
    "#     else 'small_dog' if 'chihuahua' in x \n",
    "#     else 'small_dog' if 'terrier' in x \n",
    "#     else 'small_dog' if 'dachshund' in x \n",
    "#     else 'small_dog' if 'poodle' in x \n",
    "#     else 'small_dog' if 'jack_russell' in x \n",
    "#     else 'small_dog' if 'russell_terrier' in x \n",
    "#     else x)   \n",
    "# ##########################\n",
    "# # color \n",
    "# color_combinations = df['color'].str.split('/') # Split the color column by '/'\n",
    "# split_colors = color_combinations.apply(lambda x: [part.split()[0] for part in x] if isinstance(x, list) else []) # get the first word of each component\n",
    "\n",
    "# df['color_primary'] = split_colors.apply(lambda x: x[0] if len(x) > 0 else None)  # First color\n",
    "# df['color_secondary'] = split_colors.apply(lambda x: x[1] if len(x) > 1 else None)  # Second color\n",
    "\n",
    "# # single-color groups\n",
    "# single_colors = df[df['color_secondary'].isnull()]['color_primary'] # get single-color records\n",
    "\n",
    "# percentage_limit  = 0.05\n",
    "# single_color_counts = single_colors.value_counts()\n",
    "# total_single = single_colors.count()\n",
    "# dominant_single_colors = single_color_counts[single_color_counts / total_single >percentage_limit].index\n",
    "\n",
    "# df['single_color_group'] = df['color_primary'].apply(\n",
    "#     lambda x: x if x in dominant_single_colors else 'other_single_colour'\n",
    "# ) \n",
    "\n",
    "# # two-color combinations\n",
    "# df['sorted_combination'] = df.apply(\n",
    "#     lambda row: tuple(sorted([row['color_primary'], row['color_secondary']]))\n",
    "#     if pd.notnull(row['color_secondary']) else None,\n",
    "#     axis=1\n",
    "# )\n",
    "\n",
    "# percentage_limit_combinations = 0.05\n",
    "# combination_counts = df['sorted_combination'].dropna().value_counts()\n",
    "# total_combinations = combination_counts.sum()\n",
    "# dominant_combinations = combination_counts[combination_counts / total_combinations > percentage_limit_combinations].index\n",
    "\n",
    "# df['combination_group'] = df['sorted_combination'].apply(\n",
    "#     lambda x: x if x in dominant_combinations else 'other_multiple_color'\n",
    "# ) \n",
    "\n",
    "# # final color group assignment\n",
    "# df['color_group'] = df.apply(\n",
    "#     lambda row: row['single_color_group']\n",
    "#     if pd.isnull(row['sorted_combination'])\n",
    "#     else row['combination_group'],\n",
    "#     axis=1\n",
    "# )\n",
    "# df['color_group'] = df['color_group'].apply(\n",
    "#     lambda x: ' & '.join(x) if isinstance(x, tuple) else x  # Convert tuples to readable strings\n",
    "# ) \n",
    "\n",
    "# ##########################\n",
    "# # in sex_upon_intake column, just add if is male or not to avoid having unknown values\n",
    "# df['is_male'] = df['sex_upon_intake'].apply(lambda x: 1 if x =='male' else 0) \n",
    "# # condition at intake: grouping medical (med attn and medical), normal, sick_injured and rest (other)\n",
    "# df['intake_condition_group'] = df['intake_condition'].apply(\n",
    "#     lambda x: 'normal' if 'normal' in x \n",
    "#     else 'sick_injured' if 'sick' in x \n",
    "#     else 'sick_injured' if 'injured' in x \n",
    "#     else 'medical' if 'medical' in x \n",
    "#     else 'medical' if 'med attn' in x  \n",
    "#     else 'nursing' if 'nursing' in x \n",
    "#     else 'nursing' if 'neonatal' in x \n",
    "#     else 'other')\n",
    "\n",
    "# # group intake type: stray, owner surrended and Other\n",
    "# df['intake_type_group'] = df['intake_type'].apply(\n",
    "#     lambda x: 'stray' if 'stray' in x \n",
    "#     else 'owner surrender' if 'owner surrender' in x \n",
    "#     else 'other'\n",
    "# )\n",
    "\n",
    "\n",
    "\n",
    "# ####################\n",
    "# # is dog\n",
    "# df['is_dog'] = df['animal_type'].apply(lambda x: 1 if x =='dog' else 0)\n",
    "# ######################\n",
    "# # day of intake mothn and day of week\n",
    "# df['day_of_week_in'] = df['datetime_intake'].dt.day_of_week\n",
    "# df['month_in'] = df['datetime_intake'].dt.month\n",
    "\n",
    "# #####################\n",
    "# # Function to calculate the overlap count for a given row, considering animal_type\n",
    "# def count_overlapping_by_type(row, df):\n",
    "#     overlapping = df[\n",
    "#         (df['datetime_intake'] <= row['datetime_outcome']) &  # Shelter intake is before or during this outcome\n",
    "#         (df['datetime_outcome'] >= row['datetime_intake']) &  # Shelter outcome is after or during this intake\n",
    "#        ##(df['animal_type'] == row['animal_type']) &           # Same animal type\n",
    "#        ## (df['breed_group'] == row['breed_group']) &        # Same day of the week\n",
    "#         (df.index != row.name)  # Exclude the current record itself\n",
    "#     ]\n",
    "#     return len(overlapping) \n",
    "# df['animals_in_shelter'] = df.apply(lambda row: count_overlapping_by_type(row, df), axis=1)\n",
    "\n",
    "\n",
    "# # drop the columns that are not useful \n",
    "# del df['name'] \n",
    "# del df['age_upon_intake']\n",
    "# del df['breed_group1']\n",
    "# del df['breed_group2']\n",
    "# del df['breed']\n",
    "# del df['breed_tokenized']\n",
    "# del df['color']\n",
    "# del df['color_primary']\n",
    "# del df['color_secondary']   \n",
    "# del df['single_color_group']\n",
    "# del df['sorted_combination']\n",
    "# del df['combination_group']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"3\">3. Model evaluation</h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"31\">3.1 Features selection pre-model</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['animal_id', 'datetime_intake', 'found_location', 'intake_type',\n",
       "       'intake_condition', 'animal_type', 'sex_upon_intake',\n",
       "       'datetime_outcome', 'outcome_type', 'days_in_shelter', 'castrated',\n",
       "       'is_castrated', 'age_in_months', 'hair_type', 'mix_breed',\n",
       "       'is_mix_breed', 'miniature', 'is_miniature', 'domestic', 'is_domestic',\n",
       "       'breed_group', 'color_group', 'is_male', 'intake_condition_group',\n",
       "       'intake_type_group', 'is_dog', 'day_of_week_in', 'month_in',\n",
       "       'animals_in_shelter'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = [\n",
    "    'age_in_months', \n",
    "    'month_in', \n",
    "    'animals_in_shelter',\n",
    "    'day_of_week_in',\n",
    "    'is_dog',\n",
    "    'is_mix_breed', \n",
    "    'is_miniature', \n",
    "    'is_domestic',\n",
    "    'is_castrated'] \n",
    "  \n",
    "categorical = [    \n",
    "    'intake_type_group',\n",
    "    'intake_condition_group',  \n",
    "    'is_male', \n",
    "    'hair_type',\n",
    "   # 'day_of_week_in',\n",
    "     'breed_group',     \n",
    "     'color_group'\n",
    "]\n",
    "#   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in numerical columns:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "Missing values in categorical columns:\n",
      "Series([], dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# checckiing for missing values in columns inside numerical or categorical\n",
    "missing_numerical = df[numerical].isnull().sum()\n",
    "missing_categorical = df[categorical].isnull().sum()\n",
    "\n",
    "print(f\"Missing values in numerical columns:\\n{missing_numerical[missing_numerical > 0]}\\n\")\n",
    "print(f\"Missing values in categorical columns:\\n{missing_categorical[missing_categorical > 0]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"32\">3.2 Training models</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training the model we will use the whole dataset except the last 20% of the records ordered by datetime_intake that would be the test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the training dataset, validation and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test df from:  2022-06-22 12:20:00 test df to:  2024-11-10 13:10:00\n"
     ]
    }
   ],
   "source": [
    "# for test: last 20% of the records based on the datetime_intake column\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df_test = df.sort_values('datetime_intake').tail(int(len(df) * 0.2))\n",
    "print('test df from: ',df_test['datetime_intake'].min(), 'test df to: ' ,df_test['datetime_intake'].max())\n",
    "\n",
    "# for train: the rest of the records that I will divide into train and validation sets\n",
    "df_full_train = df.drop(df_test.index).reset_index(drop=True)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.20, random_state=1)\n",
    "\n",
    "df_full_train = df_full_train.reset_index(drop=True)\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_full_train = df_full_train.days_in_shelter.values\n",
    "y_train = df_train.days_in_shelter.values\n",
    "y_val = df_val.days_in_shelter.values\n",
    "y_test = df_test.days_in_shelter.values\n",
    "\n",
    "del df_full_train['days_in_shelter']\n",
    "del df_train['days_in_shelter']\n",
    "del df_val['days_in_shelter']\n",
    "del df_test['days_in_shelter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dict = df_train[categorical + numerical].to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dict = df_val[categorical + numerical].to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)  # Use transform, not fit_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_dict = df_full_train[categorical + numerical].to_dict(orient='records')\n",
    "X_full_train = dv.transform(full_train_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dict = df_test[categorical + numerical].to_dict(orient='records')\n",
    "X_test = dv.transform(test_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age_in_months', 'animals_in_shelter', 'breed_group=Other', 'breed_group=australian_shepherd', 'breed_group=australian_tle', 'breed_group=black_mouth', 'breed_group=border_collie', 'breed_group=boxer', 'breed_group=german_shepherd', 'breed_group=great_pyrenees', 'breed_group=hound', 'breed_group=labrador_retriever', 'breed_group=larger_dangerous', 'breed_group=siamese', 'breed_group=siberian_husky', 'breed_group=small_dog', 'color_group=black', 'color_group=black & brown', 'color_group=black & tan', 'color_group=black & white', 'color_group=blue', 'color_group=blue & white', 'color_group=brown', 'color_group=brown & white', 'color_group=orange', 'color_group=other_multiple_color', 'color_group=other_single_colour', 'color_group=tan', 'color_group=tan & white', 'color_group=tricolor', 'color_group=white', 'day_of_week_in', 'hair_type=long', 'hair_type=medium', 'hair_type=short', 'hair_type=unknown', 'intake_condition_group=medical', 'intake_condition_group=normal', 'intake_condition_group=nursing', 'intake_condition_group=other', 'intake_condition_group=sick_injured', 'intake_type_group=other', 'intake_type_group=owner surrender', 'intake_type_group=stray', 'is_castrated', 'is_dog', 'is_domestic', 'is_male', 'is_miniature', 'is_mix_breed', 'month_in']\n"
     ]
    }
   ],
   "source": [
    "print(dv.feature_names_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "import xgboost as xgb\n",
    " \n",
    "features = list(dv.get_feature_names_out()) \n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=features)\n",
    "dval = xgb.DMatrix(X_val, label=y_val, feature_names=features)\n",
    "\n",
    "# Watchlist for monitoring training and validation\n",
    "watchlist = [(dtrain, 'train'), (dval, 'val')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final model\n",
    "# Train the final model with optimal hyperparameters\n",
    "xgb_params = {\n",
    "    'eta': 0.1,                    \n",
    "    'max_depth': 6,                \n",
    "    'gamma': 0.1,                  \n",
    "    'subsample': 0.8,              \n",
    "    'colsample_bytree': 0.8,       \n",
    "    'min_child_weight': 15,        \n",
    "    'objective': 'reg:squarederror',\n",
    "    'nthread': -1,                 \n",
    "    'seed': 1,                     \n",
    "    'verbosity': 1,                \n",
    "    'eval_metric': 'rmse'                \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-rmse:31.53376\tval-rmse:31.32161\n",
      "[5]\ttrain-rmse:21.95944\tval-rmse:21.91448\n",
      "[10]\ttrain-rmse:16.33567\tval-rmse:16.43894\n",
      "[15]\ttrain-rmse:13.18411\tval-rmse:13.42728\n",
      "[20]\ttrain-rmse:11.55946\tval-rmse:11.89706\n",
      "[25]\ttrain-rmse:10.65552\tval-rmse:11.07049\n",
      "[30]\ttrain-rmse:10.15637\tval-rmse:10.61791\n",
      "[35]\ttrain-rmse:9.88664\tval-rmse:10.40141\n",
      "[40]\ttrain-rmse:9.76418\tval-rmse:10.30913\n",
      "[45]\ttrain-rmse:9.68331\tval-rmse:10.26511\n",
      "[50]\ttrain-rmse:9.60270\tval-rmse:10.21823\n",
      "[55]\ttrain-rmse:9.55257\tval-rmse:10.19293\n",
      "[60]\ttrain-rmse:9.50368\tval-rmse:10.16764\n",
      "[65]\ttrain-rmse:9.46555\tval-rmse:10.14825\n",
      "[70]\ttrain-rmse:9.42785\tval-rmse:10.13125\n",
      "[75]\ttrain-rmse:9.39144\tval-rmse:10.11717\n",
      "[80]\ttrain-rmse:9.36862\tval-rmse:10.11293\n",
      "[85]\ttrain-rmse:9.34698\tval-rmse:10.11335\n",
      "[90]\ttrain-rmse:9.30707\tval-rmse:10.10562\n",
      "[95]\ttrain-rmse:9.28346\tval-rmse:10.10230\n",
      "[100]\ttrain-rmse:9.24718\tval-rmse:10.09624\n",
      "[105]\ttrain-rmse:9.22805\tval-rmse:10.09146\n",
      "[110]\ttrain-rmse:9.20983\tval-rmse:10.08727\n",
      "[115]\ttrain-rmse:9.17874\tval-rmse:10.07765\n",
      "[120]\ttrain-rmse:9.15254\tval-rmse:10.06972\n",
      "[125]\ttrain-rmse:9.12530\tval-rmse:10.06499\n",
      "[130]\ttrain-rmse:9.10553\tval-rmse:10.06349\n",
      "[135]\ttrain-rmse:9.08154\tval-rmse:10.06000\n",
      "[140]\ttrain-rmse:9.06147\tval-rmse:10.05471\n",
      "[145]\ttrain-rmse:9.03793\tval-rmse:10.04768\n",
      "[150]\ttrain-rmse:9.02582\tval-rmse:10.04766\n",
      "[155]\ttrain-rmse:9.00130\tval-rmse:10.04274\n",
      "[160]\ttrain-rmse:8.98100\tval-rmse:10.04310\n",
      "[165]\ttrain-rmse:8.95780\tval-rmse:10.04398\n",
      "[168]\ttrain-rmse:8.94455\tval-rmse:10.04238\n",
      "Validation RMSE: 10.042384808836292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(\n",
    "    xgb_params,\n",
    "    dtrain,\n",
    "    num_boost_round=200,  # Maximum boosting rounds\n",
    "    evals=[(dtrain, 'train'), (dval, 'val')],  # Monitor train and validation RMSE\n",
    "    verbose_eval=5,  # Print every 5 rounds\n",
    "    early_stopping_rounds=5  # Stop if no improvement for 10 rounds\n",
    ")\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_pred = model.predict(dval)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "print(f\"Validation RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Validation RMSE: 10.044178004245143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = xgb.train(\n",
    "    xgb_params,\n",
    "    dtrain,\n",
    "    num_boost_round=171\n",
    ")\n",
    "\n",
    "y_pred = model.predict(dval)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "print(f\"Final Validation RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 10.299410796312996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/ml-zoomcamp/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set with full training data\n",
    "dtest = xgb.DMatrix(X_test, feature_names=features)\n",
    "y_pred = model.predict(dtest)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "print(f\"Test RMSE: {rmse}\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
